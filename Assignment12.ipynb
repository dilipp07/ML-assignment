{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111120c6",
   "metadata": {},
   "source": [
    "# 1. What is prior probability ? Give an example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d6217",
   "metadata": {},
   "source": [
    "\n",
    "Prior probability, also known as prior belief or prior distribution, refers to the initial probability assigned to an event or hypothesis before any specific evidence or data is taken into account. It represents the degree of belief in the event or hypothesis based on general knowledge, assumptions, or previous experience.\n",
    "\n",
    "Let's say you are trying to determine the probability of a person being a smoker. Before you gather any data or evidence specific to the individual, you might have a prior belief or prior probability based on general knowledge or assumptions. Let's say your prior belief is that in the general population, approximately 20% of people are smokers.\n",
    "\n",
    "So, in this example, the prior probability of a randomly selected person being a smoker is 0.2 or 20%. This is your initial belief before considering any individual characteristics or data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae857d4",
   "metadata": {},
   "source": [
    "# 2. What is posterior probability ? Give an example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c74bcef",
   "metadata": {},
   "source": [
    "\n",
    "Posterior probability, in Bayesian inference, refers to the updated probability of an event or hypothesis after considering new evidence or data. It is obtained by combining the prior probability with the likelihood of the data given the hypothesis. The posterior probability represents the revised degree of belief in the event or hypothesis based on the available information.\n",
    "\n",
    "Let's continue with the example of determining the probability of a person being a smoker. Suppose you have gathered some data about an individual, such as their age, occupation, and health condition, and you want to update your prior belief based on this information.\n",
    "\n",
    "Initially, your prior probability was 0.2 or 20% based on general knowledge. Now, after considering the individual's data, you can calculate the posterior probability.\n",
    "\n",
    "Let's assume that based on the individual's data, you find that smokers are more likely to be in the age group of 25-40, work in high-stress occupations, and have a history of respiratory issues. The individual matches these characteristics.\n",
    "\n",
    "Posterior probability = (Likelihood × Prior probability) / Evidence\n",
    "\n",
    "Posterior probability = (0.6 × 0.2) / Evidence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c981ac1e",
   "metadata": {},
   "source": [
    "# 3. What is likelihood probability ? Give an example ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618f0f7",
   "metadata": {},
   "source": [
    "Likelihood probability, in Bayesian inference, refers to the probability of observing a given set of data or evidence, assuming a particular hypothesis or parameter value. It quantifies the compatibility of the observed data with the hypothesis or parameter value under consideration.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ab2a64",
   "metadata": {},
   "source": [
    "# 4. What is Naïve Bayes classifier ? Why is it named so ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea164d",
   "metadata": {},
   "source": [
    " Naive Bayes is a simple and powerful algorithm for predictive modeling. Naive Bayes is called naive because it assumes that each input variable is independent. This is a strong assumption and unrealistic for real data; however, the technique is very effective on a large range of complex problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be2162e",
   "metadata": {},
   "source": [
    "# 5. What is optimal Bayes classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7abae5",
   "metadata": {},
   "source": [
    " The Bayes Optimal Classifier is a probabilistic model that makes the most probable prediction for a new example. Bayes Optimal Classifier is a probabilistic model that finds the most probable prediction using the training data and space of hypotheses to make a prediction for a new data instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96163dd",
   "metadata": {},
   "source": [
    "# 6. Write any two features of Bayesian learning methods ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09004071",
   "metadata": {},
   "source": [
    " A probability distribution over observed data for each possible hypothesis. New instances can be classified by combining the predictions of multiple hypotheses, weighted by their probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b649e",
   "metadata": {},
   "source": [
    "# 7. Define the concept of consistent learners ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eba4091",
   "metadata": {},
   "source": [
    "Consistent Learners: A learner L using a hypothesis H and training data D is said to be a consistent learner if it  always outputs a hypothesis with zero error on D whenever H contains such a hypothesis. • By definition, a consistent learner must produce a hypothesis in the version space for H given D. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54020cf8",
   "metadata": {},
   "source": [
    "# 8. Write any two strengths of Bayes classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28211a96",
   "metadata": {},
   "source": [
    "This algorithm works quickly and can save a lot of time. Naive Bayes is suitable for solving multi-class prediction problems. If its assumption of the independence of features holds true, it can perform better than other models and requires much less training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db681d1",
   "metadata": {},
   "source": [
    "# 9. Write any two weaknesses of Bayes classifier ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7646cf4",
   "metadata": {},
   "source": [
    " The greatest weakness of the naïve Bayes classifier is that it relies on an often-faulty assumption of equally important and independent features which results in biased posterior probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b686929",
   "metadata": {},
   "source": [
    "# 10. Explain how Naïve Bayes classifier is used for:\n",
    "1. Text classification\n",
    "2. Spam filtering\n",
    "3. Market sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8447d36",
   "metadata": {},
   "source": [
    "\n",
    "Text Classification:\n",
    "\n",
    "Text classification involves assigning predefined categories or labels to text documents based on their content. Naïve Bayes is commonly used for text classification due to its simplicity and effectiveness. The algorithm treats each word or feature in the text as independent of others (hence \"naïve\"), which simplifies the computations.\n",
    "To use Naïve Bayes for text classification, the algorithm is trained on a labeled dataset, where each document is associated with a category. It learns the statistical properties of the words in each category and builds a probabilistic model. When a new, unlabeled document is encountered, the classifier calculates the posterior probability of each category given the document's words using Bayes' theorem. The category with the highest probability is assigned to the document.\n",
    "\n",
    "Spam Filtering:\n",
    "\n",
    "Spam filtering aims to distinguish between legitimate emails and unwanted spam emails. Naïve Bayes is particularly effective for this task because it can handle high-dimensional feature spaces efficiently.\n",
    "To apply Naïve Bayes for spam filtering, the algorithm is trained on a dataset of labeled emails, where each email is labeled as either spam or not spam. The classifier learns the probability distribution of words in spam and non-spam emails. When a new email arrives, it calculates the posterior probability of the email being spam or non-spam based on the presence of certain words or features. If the probability exceeds a certain threshold, the email is classified as spam.\n",
    "\n",
    "Market Sentiment Analysis:\n",
    "\n",
    "Market sentiment analysis involves determining the sentiment or opinion expressed in market-related texts, such as news articles, social media posts, or financial reports. It helps gauge the overall sentiment of the market towards specific stocks, companies, or economic indicators.\n",
    "Naïve Bayes can be utilized for market sentiment analysis by training the classifier on a labeled dataset of market-related texts associated with positive, negative, or neutral sentiments. The algorithm learns the statistical properties of words or features in each sentiment category. When new texts are encountered, the classifier calculates the posterior probability of each sentiment given the words in the text. The sentiment with the highest probability is assigned to the text, indicating the market sentiment expressed in it.\n",
    "\n",
    "In all three applications, Naïve Bayes leverages the probabilistic framework of Bayes' theorem to make predictions based on statistical patterns in the training data. While it assumes independence between features, the algorithm often performs well in practice and can be a useful tool for classification tasks involving text data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
